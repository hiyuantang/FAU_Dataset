train_loss at epoch0: 0.050493549555540085
train_mses at epoch0: [5.67246287e+00 1.43240103e-02 2.37973669e-03 2.65462715e-03
 8.81742372e-02 2.55090878e-03 5.30891759e-03 3.11311702e-03
 1.02954396e-01 1.35503586e-02]
train_maes at epoch0: [2.3790617  0.09420301 0.04873373 0.04800632 0.29065109 0.04800339
 0.07285331 0.05359203 0.28202312 0.11640494]
test_loss at epoch0: 0.041842903941869736
test_mses at epoch0: [2.99166343e+00 1.89263558e-02 1.26536809e-02 2.75495668e-02
 2.29314383e-01 1.83495815e-02 1.87558419e-03 1.23955998e-02
 3.75160208e-02 3.05993892e-03]
test_maes at epoch0: [1.6591146  0.12055544 0.08875629 0.14384403 0.40747564 0.13428394
 0.04189215 0.10334028 0.19365136 0.05385906]

train_loss at epoch1: 0.018994813784956932
train_mses at epoch1: [2.12319014e+00 2.53726869e-03 1.18996572e-03 3.94622970e-03
 2.02708391e-02 3.74431791e-03 1.27360711e-02 3.61731261e-04
 4.08687470e-02 3.79603722e-03]
train_maes at epoch1: [1.45625311 0.03645172 0.03449492 0.05335898 0.14131565 0.05820443
 0.08472823 0.01431552 0.18153858 0.06108862]
test_loss at epoch1: 0.02317129634320736
test_mses at epoch1: [1.48087902 0.01159327 0.0064097  0.01884463 0.1203832  0.02134353
 0.00378919 0.01973384 0.01243912 0.0028979 ]
test_maes at epoch1: [1.16950226 0.09416449 0.06006228 0.12070543 0.28432643 0.14376827
 0.05989236 0.13040704 0.11124437 0.05298013]

train_loss at epoch2: 0.014857691712677479
train_mses at epoch2: [1.91786966e+00 4.75040018e-03 5.51038836e-04 1.17249990e-03
 6.00435274e-03 5.55051230e-04 9.08368564e-03 2.29733837e-03
 1.53227629e-02 5.12232927e-03]
train_maes at epoch2: [1.38430887 0.06299371 0.02211281 0.03339339 0.07598755 0.01771516
 0.07351575 0.04447408 0.09478458 0.0714087 ]
test_loss at epoch2: 0.014665394090116024
test_mses at epoch2: [0.69169098 0.00603463 0.00321416 0.0121995  0.07061498 0.02686652
 0.00542052 0.0301508  0.00442006 0.00267766]
test_maes at epoch2: [0.80531195 0.06916445 0.04373955 0.09776612 0.21004713 0.16113197
 0.07198845 0.1626555  0.0649952  0.05087196]

train_loss at epoch3: 0.006178530398756266
train_mses at epoch3: [6.58355836e-01 2.72541093e-03 2.28326719e-03 2.61964067e-04
 1.40197118e-03 1.13017809e-03 1.40967477e-02 5.32155143e-05
 4.97317333e-03 5.32103895e-03]
train_maes at epoch3: [0.80302492 0.03976378 0.04547345 0.01597954 0.029702   0.03105065
 0.09740057 0.00577541 0.06656572 0.07110127]
test_loss at epoch3: 0.01103880349546671
test_mses at epoch3: [0.32265209 0.00300431 0.00146159 0.00847222 0.04332123 0.03035334
 0.00572902 0.04431741 0.00205882 0.00225437]
test_maes at epoch3: [0.55652103 0.05049562 0.03233456 0.08160741 0.16023988 0.17188746
 0.0733672  0.20021529 0.04287615 0.04663137]

train_loss at epoch4: 0.0035427638795226812
train_mses at epoch4: [3.05851018e-01 3.83239386e-03 2.79744410e-04 2.84900926e-04
 3.78362749e-03 4.50191400e-03 6.84103163e-03 3.51506768e-04
 1.48148922e-03 4.13081152e-03]
train_maes at epoch4: [0.55156127 0.06001019 0.01219294 0.01624165 0.05564811 0.05745762
 0.07897353 0.01706645 0.03343241 0.05510081]
test_loss at epoch4: 0.009390304796397686
test_mses at epoch4: [0.1428296  0.0014786  0.00062579 0.00606735 0.02457751 0.03070744
 0.0054271  0.0610081  0.00113883 0.00174461]
test_maes at epoch4: [0.37496059 0.03769587 0.02389444 0.06993069 0.11608771 0.17354572
 0.0705406  0.23827299 0.03067751 0.04124132]

train_loss at epoch5: 0.002628522692248225
train_mses at epoch5: [1.13770163e-01 1.06579560e-04 1.71535311e-04 5.75728517e-04
 3.36886732e-04 3.86217382e-03 1.75190724e-02 1.99027726e-04
 4.93802982e-05 7.13991252e-03]
train_maes at epoch5: [0.31424087 0.00851897 0.0128426  0.02319701 0.01681441 0.04476132
 0.10167209 0.01405689 0.00641301 0.08067877]
test_loss at epoch5: 0.008825309574604034
test_mses at epoch5: [0.06186835 0.0008984  0.00033606 0.00455221 0.0136787  0.02826249
 0.00406462 0.07808178 0.00075391 0.00122546]
test_maes at epoch5: [0.24870808 0.02986071 0.0182745  0.06105581 0.08356992 0.1671595
 0.05954094 0.27214946 0.0240349  0.0348821 ]

train_loss at epoch6: 0.0023939076345413923
train_mses at epoch6: [8.35579239e-02 1.72422440e-03 4.52821845e-04 7.60308673e-04
 2.56686107e-04 2.01649240e-03 1.73483172e-02 3.49022293e-03
 5.77203246e-05 3.13806167e-03]
train_maes at epoch6: [0.289057   0.03702691 0.02062566 0.02657436 0.01432119 0.03562896
 0.12214559 0.05887217 0.00725177 0.04662242]
test_loss at epoch6: 0.008515247143805027
test_mses at epoch6: [0.0231059  0.00077396 0.00023964 0.00325046 0.00770969 0.02476066
 0.0023844  0.09019055 0.00064904 0.0008359 ]
test_maes at epoch6: [0.15027772 0.02496122 0.01279986 0.05233652 0.06768313 0.15700281
 0.04354897 0.29432586 0.02181127 0.02891081]

train_loss at epoch7: 0.001107363379560411
train_mses at epoch7: [0.01080878 0.00053471 0.00062612 0.00022853 0.00025524 0.00229435
 0.00438824 0.00384206 0.00034093 0.00373683]
train_maes at epoch7: [0.10394646 0.02159728 0.02464492 0.01510995 0.01295788 0.04427723
 0.06623312 0.04764084 0.01541083 0.05456773]
test_loss at epoch7: 0.008225436322391033
test_mses at epoch7: [0.00755972 0.00091489 0.00024637 0.00257503 0.00448911 0.02106715
 0.00125535 0.09614876 0.0005687  0.00051886]
test_maes at epoch7: [0.07776943 0.02159497 0.01305877 0.04685695 0.05612267 0.14507657
 0.0279537  0.30522642 0.02005909 0.02255292]

train_loss at epoch8: 0.0007362490869127214
train_mses at epoch8: [2.63774648e-02 2.58395918e-04 3.85946665e-04 4.99307528e-04
 5.36356928e-04 1.09238637e-03 2.57770998e-04 4.60527596e-03
 2.45035495e-05 1.26802236e-03]
train_maes at epoch8: [0.16201034 0.01180477 0.01475245 0.01752172 0.01885515 0.02627459
 0.01601231 0.06341044 0.00428563 0.0344442 ]
test_loss at epoch8: 0.007759318687021732
test_mses at epoch8: [0.00299049 0.00115495 0.00024357 0.00208483 0.00282402 0.01858369
 0.00068481 0.0945706  0.00051828 0.00028257]
test_maes at epoch8: [0.04846396 0.028197   0.01419699 0.04204871 0.04755988 0.13632125
 0.02141403 0.30339268 0.01865665 0.01589068]

train_loss at epoch9: 0.0009167122771032155
train_mses at epoch9: [1.56252517e-03 9.57989947e-06 2.41917933e-04 4.86224444e-04
 7.96777269e-05 3.09308363e-03 1.84324035e-03 5.55373274e-03
 1.87591241e-04 2.67599048e-03]
train_maes at epoch9: [0.03933284 0.00309126 0.01496218 0.01902385 0.00844442 0.04279473
 0.03184545 0.07336845 0.01006377 0.05097034]
test_loss at epoch9: 0.006979655008763075
test_mses at epoch9: [0.00314061 0.00138104 0.00025648 0.00168755 0.00194344 0.01566107
 0.00046392 0.08666733 0.00055968 0.00012989]
test_maes at epoch9: [0.05388148 0.03310816 0.01532063 0.03750491 0.04128395 0.12503424
 0.02116849 0.29075686 0.01928565 0.00831222]

train_loss at epoch10: 0.0007559110526926816
train_mses at epoch10: [2.09997847e-03 1.92802665e-05 2.71353954e-05 3.91235547e-04
 4.07561944e-04 1.76791898e-03 7.59829286e-04 3.65002295e-03
 1.24055236e-04 4.45899372e-03]
train_maes at epoch10: [0.04580742 0.00410262 0.00511476 0.01555436 0.01871255 0.04095774
 0.0253603  0.06011709 0.00893139 0.0477154 ]
test_loss at epoch10: 0.006070788949728012
test_mses at epoch10: [5.33404533e-03 1.53734486e-03 2.65118541e-04 1.41408783e-03
 1.46161376e-03 1.27213252e-02 4.61557653e-04 7.57893669e-02
 5.85736751e-04 9.90232928e-05]
test_maes at epoch10: [0.05641614 0.03623885 0.01602611 0.03336904 0.03663992 0.1124052
 0.02078047 0.27203491 0.01973198 0.0099337 ]

train_loss at epoch11: 0.0006891636294312775
train_mses at epoch11: [0.03623125 0.00140126 0.00060132 0.00026401 0.00055587 0.00012891
 0.00012809 0.00270686 0.00033963 0.00110402]
train_maes at epoch11: [0.17018542 0.03663301 0.0228034  0.01234283 0.02335749 0.00877328
 0.00858903 0.05130514 0.01839085 0.03321835]
test_loss at epoch11: 0.005075862165540457
test_mses at epoch11: [0.00662979 0.00143586 0.00017788 0.00123775 0.00116309 0.01139752
 0.0005408  0.06197542 0.00055717 0.0001774 ]
test_maes at epoch11: [0.05884044 0.0353587  0.01314101 0.0296762  0.03266042 0.10598615
 0.02010346 0.2460596  0.01930595 0.01140984]

train_loss at epoch12: 0.0005706801894120872
train_mses at epoch12: [2.46607374e-02 1.52981064e-04 4.50072621e-04 3.04326703e-05
 2.98623297e-05 1.63495005e-04 6.45636463e-05 3.40196642e-03
 1.43813962e-03 7.77089328e-04]
train_maes at epoch12: [0.14944029 0.01185016 0.02073895 0.00512773 0.00498811 0.0112811
 0.0059027  0.04515531 0.03732254 0.02401396]
test_loss at epoch12: 0.004096251912415028
test_mses at epoch12: [6.67988716e-03 1.24484473e-03 7.22094233e-05 1.12486458e-03
 9.49975568e-04 1.06599505e-02 6.44638402e-04 4.78803465e-02
 4.78042445e-04 2.96727807e-04]
test_maes at epoch12: [0.06042701 0.03299605 0.00812443 0.02640824 0.02904809 0.10193717
 0.01919354 0.21628997 0.01773358 0.01219658]

train_loss at epoch13: 0.0002821448724716902
train_mses at epoch13: [1.84704192e-04 1.91460971e-04 2.22369175e-04 6.93676525e-04
 5.80694832e-05 8.44861718e-04 4.92887579e-04 1.52050957e-03
 1.89154337e-04 1.77486814e-04]
train_maes at epoch13: [0.01136041 0.01096242 0.01483666 0.0259148  0.00647591 0.0272105
 0.02198277 0.03771981 0.01093676 0.0131804 ]
test_loss at epoch13: 0.0032332097180187702
test_mses at epoch13: [6.35481902e-03 1.04582079e-03 1.42189676e-05 9.77136959e-04
 7.89246566e-04 1.00151807e-02 7.53404420e-04 3.54490140e-02
 4.10909402e-04 4.43382738e-04]
test_maes at epoch13: [0.05911574 0.03007542 0.00296507 0.02337664 0.02575783 0.09802743
 0.02047214 0.18606197 0.01625029 0.01687218]

train_loss at epoch14: 0.0003735769132617861
train_mses at epoch14: [0.00697619 0.00029517 0.00035618 0.0001975  0.00017439 0.00131879
 0.00044871 0.00092494 0.00103967 0.00040052]
train_maes at epoch14: [0.07728559 0.01718017 0.01689399 0.01297403 0.01317997 0.03545595
 0.01713161 0.02979011 0.0262501  0.01793579]
test_loss at epoch14: 0.0025155749171972275
test_mses at epoch14: [5.48826899e-03 8.27025023e-04 1.87665476e-05 8.37384615e-04
 7.13520628e-04 9.55125725e-03 8.28016222e-04 2.51031719e-02
 3.30413175e-04 5.60339327e-04]
test_maes at epoch14: [0.05298722 0.02636283 0.00339243 0.02064831 0.02317577 0.09478483
 0.02285917 0.15652097 0.01417375 0.01999177]

train_loss at epoch15: 0.0005422236281447113
train_mses at epoch15: [0.00813907 0.00098158 0.00101576 0.00034276 0.00032218 0.00225181
 0.00048852 0.0011074  0.00029813 0.00086927]
train_maes at epoch15: [0.07189554 0.02462926 0.03041549 0.01762491 0.017747   0.04713721
 0.02074876 0.0280319  0.01556059 0.0293192 ]
test_loss at epoch15: 0.0019491109997034073
test_mses at epoch15: [4.73337293e-03 6.57370517e-04 4.17044730e-05 7.46616873e-04
 6.85664341e-04 8.29759078e-03 9.02359672e-04 1.77664040e-02
 2.69571515e-04 6.25334668e-04]
test_maes at epoch15: [0.05018872 0.02314381 0.00534767 0.01995126 0.02117079 0.08709488
 0.02482243 0.13154555 0.0119901  0.02151322]

train_loss at epoch16: 0.0005532904178835452
train_mses at epoch16: [0.02201123 0.0008841  0.00119467 0.00079831 0.0007057  0.0008297
 0.00093819 0.00051955 0.00028238 0.00034302]
train_maes at epoch16: [0.14834532 0.02583767 0.03355982 0.02492195 0.02362526 0.02835844
 0.03057364 0.01745574 0.01584812 0.01790381]
test_loss at epoch16: 0.001551344757899642
test_mses at epoch16: [0.00336345 0.00046267 0.00010158 0.00072085 0.00073239 0.00819858
 0.00088533 0.0119564  0.00020139 0.00065211]
test_maes at epoch16: [0.04840852 0.0186615  0.00927971 0.02065215 0.01951917 0.08564479
 0.02485398 0.10778232 0.0106608  0.02219383]

train_loss at epoch17: 0.0003039691655430943
train_mses at epoch17: [1.95394092e-03 3.72155636e-04 2.40580643e-04 5.13742306e-04
 2.21886312e-05 6.21298279e-04 1.87495262e-03 9.55299764e-05
 1.91559862e-04 6.26695526e-04]
train_maes at epoch17: [0.0354642  0.01798453 0.01402395 0.02220796 0.00465519 0.02459257
 0.03201414 0.00973126 0.01135774 0.02436441]
test_loss at epoch17: 0.0012552131665870547
test_mses at epoch17: [0.00262665 0.00033522 0.00015193 0.00067429 0.0007813  0.00757906
 0.00082334 0.00822207 0.00014856 0.00064043]
test_maes at epoch17: [0.04754466 0.01507307 0.01175651 0.0205301  0.02130778 0.08127648
 0.02395942 0.08924856 0.01014509 0.02198754]

train_loss at epoch18: 0.0005571332876570523
train_mses at epoch18: [0.00220413 0.00051528 0.00098095 0.00029294 0.00049183 0.00307855
 0.00160572 0.00059207 0.00059827 0.00033434]
train_maes at epoch18: [0.0332807  0.02267911 0.02285759 0.017109   0.02049928 0.05026505
 0.03754026 0.02120058 0.02412694 0.01755521]
test_loss at epoch18: 0.001019504852592945
test_mses at epoch18: [0.0022486  0.00023843 0.00018062 0.00064669 0.00082937 0.00668846
 0.0007345  0.00564271 0.00012553 0.00062387]
test_maes at epoch18: [0.04688063 0.01179747 0.01307725 0.02062696 0.02339706 0.07514793
 0.02251596 0.07374333 0.00972498 0.02168688]

train_loss at epoch19: 0.0005111689097248018
train_mses at epoch19: [0.00364916 0.00036403 0.00072842 0.0003348  0.00032467 0.00205096
 0.00252367 0.00058715 0.00042729 0.00028966]
train_maes at epoch19: [0.057513   0.01829905 0.02513541 0.01752857 0.01745275 0.04527331
 0.04608922 0.01765528 0.01464567 0.01376745]
test_loss at epoch19: 0.0008667463553138077
test_mses at epoch19: [0.00218187 0.00017689 0.00020087 0.00058355 0.0008935  0.0061244
 0.00060287 0.00400714 0.00011539 0.00062522]
test_maes at epoch19: [0.04649366 0.00960638 0.01399878 0.01991581 0.02543794 0.07078261
 0.01991532 0.06194697 0.00926672 0.02185421]

train_loss at epoch20: 0.00028937155730091035
train_mses at epoch20: [8.57565902e-03 8.15764224e-04 5.05718281e-04 2.93450568e-04
 1.24775581e-04 1.56565827e-04 8.88569804e-04 4.18767524e-04
 8.30877990e-05 3.97264209e-04]
train_maes at epoch20: [0.087928   0.02583806 0.01646485 0.01367678 0.01058133 0.01018386
 0.02931119 0.02007462 0.00739845 0.01884257]
test_loss at epoch20: 0.0007682375144213438
test_mses at epoch20: [0.00239859 0.00013721 0.00020853 0.00051533 0.00095623 0.00578967
 0.00047291 0.00297582 0.00010584 0.00060794]
test_maes at epoch20: [0.04641041 0.00924472 0.01438888 0.01886058 0.02716205 0.06794967
 0.01679223 0.05318828 0.00885655 0.02154432]

train_loss at epoch21: 0.00045434129424393177
train_mses at epoch21: [6.11336170e-03 1.79260386e-03 4.14631832e-05 4.11893022e-04
 1.49934234e-04 2.85937028e-04 7.80943816e-04 1.44263820e-03
 1.90028610e-04 1.40663304e-03]
train_maes at epoch21: [0.07173665 0.03631363 0.00621452 0.0161094  0.01152854 0.01641032
 0.02722416 0.03093499 0.01324852 0.02791564]
test_loss at epoch21: 0.0006918783183209598
test_mses at epoch21: [2.69803885e-03 1.19502842e-04 2.00591030e-04 4.57195197e-04
 9.95850550e-04 5.34221606e-03 3.68281540e-04 2.38085308e-03
 9.92551839e-05 5.83372379e-04]
test_maes at epoch21: [0.04644202 0.00887452 0.01416127 0.01782593 0.02827131 0.06426104
 0.01368457 0.04741446 0.00859313 0.02105165]

train_loss at epoch22: 0.0002720957563724369
train_mses at epoch22: [5.55275710e-03 6.59032121e-05 2.89194882e-04 1.11568890e-03
 3.59414169e-04 4.99984686e-04 3.51374569e-04 8.59892160e-04
 1.27790661e-04 3.99918585e-05]
train_maes at epoch22: [0.07190834 0.00664401 0.016986   0.03275819 0.01755865 0.02234725
 0.01377016 0.02901825 0.00967425 0.00596492]
test_loss at epoch22: 0.0006176788592711091
test_mses at epoch22: [2.91080625e-03 1.07222709e-04 1.70421016e-04 3.81724512e-04
 1.00188882e-03 4.68389184e-03 2.93994038e-04 2.05921967e-03
 9.55863602e-05 5.73024185e-04]
test_maes at epoch22: [0.04653655 0.00848806 0.01302528 0.01612691 0.02868083 0.05890456
 0.01317726 0.04399285 0.00853425 0.02078988]

train_loss at epoch23: 0.000339813093887642
train_mses at epoch23: [1.90614425e-05 1.12152959e-05 3.63837017e-04 3.19845818e-04
 1.01926205e-04 2.40891704e-03 3.99836367e-05 9.50146290e-04
 7.52785172e-04 3.59061025e-04]
train_maes at epoch23: [0.00435098 0.00289911 0.01641728 0.01766975 0.00937711 0.04332963
 0.00607127 0.03077451 0.02547505 0.01641306]
test_loss at epoch23: 0.0005456448998302221
test_mses at epoch23: [3.07493970e-03 9.55460243e-05 1.34576922e-04 3.10272215e-04
 9.80686463e-04 3.85428338e-03 2.45676787e-04 1.94906418e-03
 1.00881440e-04 5.54426954e-04]
test_maes at epoch23: [0.04655899 0.00807234 0.01142755 0.01427722 0.02860427 0.05197879
 0.01287175 0.04274601 0.008776   0.02027366]

train_loss at epoch24: 0.0002258454478578642
train_mses at epoch24: [3.41921711e-04 4.62741973e-05 5.27223323e-04 1.37500464e-05
 2.20733503e-05 1.51502833e-03 5.63003729e-04 1.96702073e-04
 8.53979501e-05 5.25991236e-04]
train_maes at epoch24: [0.01737139 0.00562744 0.02052616 0.00370781 0.00466895 0.03846168
 0.01835838 0.01007852 0.00836232 0.0217991 ]
test_loss at epoch24: 0.0005048566381447017
test_mses at epoch24: [3.35303834e-03 8.52970468e-05 1.06573129e-04 2.48990335e-04
 9.65775236e-04 3.46881663e-03 2.02333920e-04 1.86004176e-03
 1.01907530e-04 5.21204588e-04]
test_maes at epoch24: [0.04647702 0.00768457 0.00987472 0.01255295 0.0285977  0.04862526
 0.01253741 0.04172647 0.00881664 0.01940404]

train_loss at epoch25: 0.00040807932964526117
train_mses at epoch25: [2.28823225e-04 1.22445918e-04 1.01171367e-04 2.22034504e-05
 5.11955909e-05 1.81580711e-03 1.08306624e-03 2.25034086e-03
 4.23781487e-04 4.83881158e-04]
train_maes at epoch25: [0.01218861 0.01105101 0.00752301 0.0044971  0.00707975 0.03367269
 0.03283403 0.04717417 0.0161879  0.01919708]
test_loss at epoch25: 0.0004987689899280667
test_mses at epoch25: [3.79408646e-03 7.30318866e-05 9.17130807e-05 2.00656082e-04
 9.65956731e-04 3.38399262e-03 1.67177421e-04 1.91498391e-03
 1.09739238e-04 5.15498557e-04]
test_maes at epoch25: [0.04605953 0.00732848 0.00880567 0.01102496 0.0288203  0.04797767
 0.01211841 0.04243576 0.00879943 0.01925665]

train_loss at epoch26: 0.0002759697090368718
train_mses at epoch26: [0.00273094 0.00052264 0.00038684 0.00011852 0.00041315 0.00069984
 0.00086947 0.00026987 0.00044043 0.00032457]
train_maes at epoch26: [0.04764743 0.01927764 0.01702381 0.01042071 0.01622009 0.02580849
 0.02889833 0.01583052 0.02024178 0.01793517]
test_loss at epoch26: 0.0004984498373232782
test_mses at epoch26: [4.13450463e-03 6.56676784e-05 7.56622597e-05 1.61878043e-04
 9.44712912e-04 3.34821358e-03 1.44542195e-04 2.01337887e-03
 1.15428614e-04 5.15033774e-04]
test_maes at epoch26: [0.04558237 0.00705901 0.00746834 0.00960422 0.0286733  0.04768998
 0.01172778 0.04364183 0.0087137  0.01930675]

train_loss at epoch27: 0.00032483317772857845
train_mses at epoch27: [3.25883848e-03 3.71856837e-05 1.00590105e-04 1.59796565e-04
 2.12084814e-04 4.70270696e-04 6.71112388e-05 2.49425305e-03
 3.01868697e-04 9.14111768e-04]
train_maes at epoch27: [0.04745349 0.00533471 0.00757002 0.01245837 0.01450911 0.01859454
 0.00813027 0.04972314 0.01608172 0.02831565]
test_loss at epoch27: 0.0005009699962101877
test_mses at epoch27: [4.43933665e-03 5.94262670e-05 6.34624813e-05 1.27985321e-04
 9.11648021e-04 3.24819979e-03 1.30543592e-04 2.22410146e-03
 1.18669962e-04 5.10089763e-04]
test_maes at epoch27: [0.04875816 0.00682323 0.00608867 0.00812061 0.02827999 0.04671664
 0.01138493 0.04601241 0.00870136 0.01924796]

train_loss at epoch28: 0.00023359568149317056
train_mses at epoch28: [2.11960575e-03 1.12537306e-04 1.42234150e-04 1.84374679e-04
 2.36555291e-04 7.76191521e-04 6.57391599e-04 9.19563369e-04
 3.63313656e-04 5.07778473e-05]
train_maes at epoch28: [0.0456356  0.00793726 0.00991374 0.01244691 0.01496732 0.02622985
 0.02042021 0.02988015 0.01906058 0.00631552]
test_loss at epoch28: 0.0005214397679083049
test_mses at epoch28: [4.87502883e-03 5.38394834e-05 5.98523453e-05 1.06043912e-04
 8.90675186e-04 3.30879309e-03 1.19786236e-04 2.51087001e-03
 1.13931766e-04 5.07626604e-04]
test_maes at epoch28: [0.0533611  0.00659695 0.00557173 0.00752567 0.02803806 0.04745706
 0.01094107 0.04904894 0.00853648 0.01926397]

train_loss at epoch29: 0.00042821449460461736
train_mses at epoch29: [0.01718124 0.00011895 0.00086483 0.00035493 0.00028272 0.00073127
 0.00101035 0.00092464 0.00019252 0.00053278]
train_maes at epoch29: [0.13027957 0.00988802 0.02586189 0.0177519  0.01672513 0.01934728
 0.0260536  0.02821015 0.01195596 0.01918914]
test_loss at epoch29: 0.0005361541407182813
test_mses at epoch29: [4.94790398e-03 5.07084602e-05 5.07447943e-05 8.72343533e-05
 8.49140806e-04 3.20712766e-03 1.14615140e-04 2.89578342e-03
 1.12810153e-04 5.26050323e-04]
test_maes at epoch29: [0.05414258 0.00636806 0.00608742 0.00716012 0.02741368 0.04655595
 0.01058644 0.05278935 0.00848792 0.01976978]

train_loss at epoch30: 0.0001323897304246202
train_mses at epoch30: [9.46759176e-04 5.95594302e-05 1.08115948e-04 1.18972003e-04
 1.16034114e-04 1.49378336e-04 1.74597532e-04 1.15951038e-03
 7.79571796e-05 1.20075979e-05]
train_maes at epoch30: [0.03042221 0.0060986  0.00835472 0.00863206 0.01009791 0.0100748
 0.01315693 0.03377634 0.00877652 0.0028215 ]
test_loss at epoch30: 0.0005625264602713287
test_mses at epoch30: [5.07783605e-03 4.60656398e-05 4.70571310e-05 7.52050316e-05
 8.02973000e-04 3.12052899e-03 1.11000073e-04 3.42963013e-03
 1.15074850e-04 5.46059031e-04]
test_maes at epoch30: [0.05548356 0.00611891 0.00650394 0.00682998 0.02669302 0.04595358
 0.01019597 0.05755216 0.00852263 0.0202758 ]

train_loss at epoch31: 0.00021377290249802172
train_mses at epoch31: [6.01374770e-03 3.80050920e-04 2.04381453e-04 9.33634335e-05
 2.70297728e-04 6.36843179e-05 2.93943252e-04 6.94220030e-05
 4.44969348e-04 9.32808677e-04]
train_maes at epoch31: [0.05894066 0.01878728 0.01342913 0.00723852 0.01355061 0.00778179
 0.01607156 0.00832942 0.01959475 0.029986  ]
test_loss at epoch31: 0.0005859761731699109
test_mses at epoch31: [5.13513002e-03 4.49666270e-05 4.96351783e-05 6.82288043e-05
 7.46608428e-04 3.02396692e-03 1.05551605e-04 3.94622850e-03
 1.22870131e-04 5.46343270e-04]
test_maes at epoch31: [0.05585253 0.00591915 0.00701917 0.00659007 0.0257519  0.04518234
 0.00975901 0.06182165 0.00862702 0.0202844 ]

train_loss at epoch32: 0.00020357235916890204
train_mses at epoch32: [2.22492882e-03 5.49340863e-04 9.87992601e-05 7.40778603e-05
 8.51819100e-06 1.71092732e-03 2.20906227e-05 3.27743573e-04
 1.00943199e-04 7.10988047e-05]
train_maes at epoch32: [0.0442256  0.01919555 0.00914187 0.00653718 0.00271413 0.03835845
 0.00412835 0.01807538 0.00906207 0.00644012]
test_loss at epoch32: 0.0006351468036882579
test_mses at epoch32: [5.66194252e-03 3.85692118e-05 5.38183080e-05 6.16004908e-05
 7.12164303e-04 3.22503703e-03 1.02614487e-04 4.49203873e-03
 1.36403944e-04 5.48998127e-04]
test_maes at epoch32: [0.0604495  0.00570409 0.00732974 0.0063488  0.02519213 0.04742882
 0.0092595  0.0660779  0.00859859 0.02036492]

train_loss at epoch33: 0.0002828568685799837
train_mses at epoch33: [5.67430434e-03 1.93391270e-04 2.86163717e-04 5.36298704e-04
 3.12855402e-05 1.25419470e-03 3.51121622e-04 1.10935199e-04
 2.03382980e-04 8.98733609e-04]
train_maes at epoch33: [0.07281819 0.01390651 0.01663787 0.0166467  0.00548237 0.02712283
 0.01576845 0.0104798  0.01370075 0.0299422 ]
test_loss at epoch33: 0.0006966426153667271
test_mses at epoch33: [6.75466660e-03 3.23630722e-05 5.64615104e-05 6.13471168e-05
 6.91604335e-04 3.64839160e-03 1.02662456e-04 4.96228823e-03
 1.42679989e-04 5.27606589e-04]
test_maes at epoch33: [0.06913887 0.00551255 0.00741425 0.00618103 0.02489671 0.05174314
 0.00867464 0.06954384 0.00844826 0.01988422]

train_loss at epoch34: 0.00017685255443211645
train_mses at epoch34: [7.26091051e-03 5.48014126e-05 2.50676855e-04 3.96766361e-05
 1.35904369e-04 7.78328958e-04 4.75998010e-05 9.71955522e-05
 1.39052813e-05 6.36158792e-04]
train_maes at epoch34: [0.07758667 0.00574398 0.01578779 0.00629882 0.01154717 0.02624253
 0.00564084 0.00800022 0.00358787 0.0224944 ]
test_loss at epoch34: 0.0007466480019502342
test_mses at epoch34: [7.73108506e-03 2.89773150e-05 5.98447527e-05 6.32442400e-05
 6.67645921e-04 3.97426985e-03 1.03392806e-04 5.36886307e-03
 1.49926440e-04 4.95220876e-04]
test_maes at epoch34: [0.07607852 0.00533746 0.00750566 0.00607024 0.02451259 0.05488651
 0.00815394 0.07239939 0.00892551 0.01911756]

train_loss at epoch35: 0.0003398324188310653
train_mses at epoch35: [7.01547454e-03 5.89975554e-05 3.12205676e-04 2.01165669e-04
 1.33182695e-04 2.33747869e-04 1.28627424e-03 1.66928156e-03
 1.85918443e-04 5.44002792e-04]
train_maes at epoch35: [0.08371359 0.006094   0.01601213 0.01210752 0.00872045 0.01212843
 0.0287693  0.03171577 0.01115057 0.01845725]
test_loss at epoch35: 0.0007745862822048366
test_mses at epoch35: [8.39626952e-03 2.75885812e-05 6.15418407e-05 6.27260096e-05
 6.34985317e-04 4.17160306e-03 9.71868690e-05 5.61864630e-03
 1.51206701e-04 4.57477290e-04]
test_maes at epoch35: [0.08047451 0.00523999 0.00759066 0.00595157 0.02393562 0.05680186
 0.00761586 0.07408247 0.00900029 0.01818579]

train_loss at epoch36: 0.00015107686340343207
train_mses at epoch36: [2.86515093e-03 8.25170735e-05 7.44058578e-05 3.06154297e-04
 4.16345362e-04 1.13484765e-04 2.34066882e-04 2.99928972e-04
 3.31721053e-04 2.22151742e-04]
train_maes at epoch36: [0.05316833 0.00791677 0.00682777 0.01591083 0.01679282 0.00759382
 0.01256678 0.0165212  0.01708225 0.01451548]
test_loss at epoch36: 0.0007925935206003487
test_mses at epoch36: [8.89648438e-03 2.64014772e-05 6.26930404e-05 6.69793800e-05
 5.86794175e-04 4.32262648e-03 9.75001726e-05 5.76664535e-03
 1.55128063e-04 4.30708865e-04]
test_maes at epoch36: [0.08363275 0.0051374  0.00762385 0.00590528 0.0230227  0.05827381
 0.00723705 0.07505815 0.00920288 0.01752176]

train_loss at epoch37: 0.00029044062830507755
train_mses at epoch37: [8.91285913e-03 4.73594052e-04 3.66343791e-04 1.60650854e-04
 7.04940014e-05 1.92379670e-03 2.07630204e-06 4.84631656e-04
 1.08956367e-04 7.71947784e-05]
train_maes at epoch37: [0.06888856 0.02149166 0.01361044 0.00957942 0.00705123 0.04093379
 0.00105411 0.02196921 0.00976035 0.00826232]
test_loss at epoch37: 0.0007997461943887174
test_mses at epoch37: [9.25123784e-03 2.47451104e-05 6.40303311e-05 7.42577428e-05
 5.41341866e-04 4.39499241e-03 9.79946363e-05 5.83379166e-03
 1.53948369e-04 4.07490121e-04]
test_maes at epoch37: [0.08593889 0.00497333 0.00760948 0.00628175 0.02209958 0.05914852
 0.00709158 0.07548044 0.0091444  0.01696266]

train_loss at epoch38: 0.0001478547928854823
train_mses at epoch38: [3.11398118e-05 1.05406523e-04 2.34411373e-04 2.37630716e-06
 5.12964111e-05 1.00119640e-03 5.00645174e-05 5.89715076e-04
 5.24755080e-05 2.20247762e-04]
train_maes at epoch38: [0.00554721 0.00986262 0.01359026 0.00142578 0.00663657 0.03115906
 0.0070609  0.02423456 0.00667681 0.01093128]
test_loss at epoch38: 0.0007958590867929161
test_mses at epoch38: [9.76140468e-03 2.41025896e-05 6.81118794e-05 8.14822223e-05
 5.09048461e-04 4.43783643e-03 1.00692134e-04 5.72874256e-03
 1.50818003e-04 3.81201554e-04]
test_maes at epoch38: [0.08897112 0.00487574 0.00758685 0.00683877 0.02143554 0.0597914
 0.00756718 0.07479205 0.00902409 0.01627283]

train_loss at epoch39: 0.00021667526743840426
train_mses at epoch39: [1.33333278e-02 2.17226550e-04 1.87520208e-04 2.02076817e-05
 1.62768805e-04 6.98221568e-04 9.60264246e-05 2.76623613e-04
 1.81400735e-04 2.43472679e-04]
train_maes at epoch39: [0.1132843  0.01440471 0.013688   0.00330062 0.01237767 0.02579356
 0.00977613 0.0126111  0.01094742 0.01559687]
test_loss at epoch39: 0.0007717750268056989
test_mses at epoch39: [9.59419388e-03 2.32817264e-05 6.75529023e-05 8.95264616e-05
 4.64083010e-04 4.25134087e-03 1.01940224e-04 5.62367895e-03
 1.42334806e-04 3.58312225e-04]
test_maes at epoch39: [0.08810622 0.00480586 0.00763269 0.00736805 0.02042277 0.05858774
 0.00782002 0.07406729 0.00852078 0.01565602]

train_loss at epoch40: 0.00015210827405098826
train_mses at epoch40: [6.70725182e-03 7.08705833e-05 8.95537103e-05 1.46616194e-04
 1.47492526e-04 7.21860869e-04 2.78627880e-05 3.45801410e-04
 1.51927734e-04 1.97008713e-05]
train_maes at epoch40: [0.06210844 0.00755592 0.0087773  0.00939181 0.00911152 0.02070103
 0.00467465 0.01633371 0.01054439 0.00389641]
test_loss at epoch40: 0.0007396018481813371
test_mses at epoch40: [9.14603496e-03 2.26364697e-05 6.47152723e-05 9.91023168e-05
 4.15965629e-04 3.96949616e-03 1.03398400e-04 5.51739603e-03
 1.30519971e-04 3.39881104e-04]
test_maes at epoch40: [0.08564651 0.00475009 0.0076706  0.0079744  0.01926021 0.05656088
 0.00803525 0.0733265  0.00841921 0.01514398]

train_loss at epoch41: 0.0002941040729638189
train_mses at epoch41: [1.24757571e-02 1.06703632e-04 1.71416833e-04 1.30470115e-05
 2.08158631e-04 6.70338155e-04 5.37764012e-04 1.42891940e-03
 1.77699692e-06 2.38915524e-04]
train_maes at epoch41: [0.1063377  0.0082603  0.01074179 0.00316866 0.012305   0.02334849
 0.02221213 0.0339348  0.00117322 0.01166885]
test_loss at epoch41: 0.0006865147734060884
test_mses at epoch41: [8.27370149e-03 2.24759095e-05 6.17611225e-05 1.09536158e-04
 3.57498149e-04 3.52368102e-03 9.76534512e-05 5.30785025e-03
 1.19730939e-04 3.18626847e-04]
test_maes at epoch41: [0.08042212 0.00473225 0.00777087 0.00856348 0.01773327 0.05300881
 0.00775309 0.07185793 0.00856538 0.01449862]

train_loss at epoch42: 0.00019837018044199795
train_mses at epoch42: [1.07087523e-02 3.74125431e-05 7.23773800e-05 8.28913693e-06
 2.67382173e-04 1.03794398e-03 3.35298399e-05 3.03609614e-04
 2.70748464e-04 2.24642273e-05]
train_maes at epoch42: [0.07382174 0.00552573 0.00850476 0.00287803 0.01488743 0.02855127
 0.00425691 0.01660165 0.01554186 0.0046606 ]
test_loss at epoch42: 0.0006314633646979928
test_mses at epoch42: [7.18403069e-03 2.31195888e-05 6.29226714e-05 1.18369610e-04
 3.05346069e-04 2.96593738e-03 9.20565710e-05 5.18511054e-03
 1.11766430e-04 3.00420614e-04]
test_maes at epoch42: [0.07339071 0.00469099 0.00791396 0.00903957 0.01624107 0.04818305
 0.00743234 0.07095243 0.00879605 0.01386935]

train_loss at epoch43: 0.0001177606318378821
train_mses at epoch43: [2.39081752e-03 1.43353602e-04 5.39611313e-04 7.91836464e-05
 6.76029584e-05 9.21545725e-05 3.57569379e-05 1.86725331e-04
 1.58695647e-04 3.03447408e-04]
train_maes at epoch43: [0.04869619 0.01046188 0.02317728 0.00829116 0.00821947 0.00894916
 0.00553024 0.01067838 0.00965422 0.01479291]
test_loss at epoch43: 0.0005893978523090482
test_mses at epoch43: [6.67797093e-03 2.35465113e-05 6.38976213e-05 1.26602141e-04
 2.68956275e-04 2.61741819e-03 8.96040755e-05 4.98894936e-03
 1.03559063e-04 2.74661751e-04]
test_maes at epoch43: [0.06996666 0.00465399 0.0079195  0.00946058 0.01512809 0.0450338
 0.00734136 0.06953221 0.00893021 0.01295382]

train_loss at epoch44: 0.0002297976752743125
train_mses at epoch44: [2.48947209e-03 4.90576774e-05 9.68727732e-04 1.57670628e-04
 1.01227590e-04 6.28390486e-04 6.10498881e-06 9.37702887e-04
 2.37016358e-05 4.74892514e-04]
train_maes at epoch44: [0.04652339 0.00625813 0.03091942 0.01175677 0.00915432 0.02417334
 0.00230127 0.02994103 0.00439627 0.01707426]
test_loss at epoch44: 0.0005579047137871385
test_mses at epoch44: [6.84053554e-03 2.32527736e-05 6.09290161e-05 1.42117636e-04
 2.48818683e-04 2.51418922e-03 9.01895176e-05 4.62650358e-03
 9.73937186e-05 2.45845249e-04]
test_maes at epoch44: [0.07117598 0.00465517 0.00780304 0.01021219 0.01451526 0.04422546
 0.00752152 0.06690672 0.00891211 0.01188753]

train_loss at epoch45: 7.189164898591116e-05
train_mses at epoch45: [4.45463815e-04 2.57616635e-05 7.44326896e-05 5.03329218e-05
 2.11945681e-06 9.12268648e-05 7.40890908e-05 5.02679935e-04
 5.16468776e-05 2.07515257e-04]
train_maes at epoch45: [0.01702157 0.00505635 0.00630091 0.00670098 0.00109154 0.00688961
 0.00772318 0.02053825 0.00566739 0.01373068]
test_loss at epoch45: 0.0005274867289699614
test_mses at epoch45: [6.97194115e-03 2.31789462e-05 5.95438527e-05 1.55151030e-04
 2.32388421e-04 2.40302903e-03 9.22708586e-05 4.28709059e-03
 9.17553964e-05 2.16718552e-04]
test_maes at epoch45: [0.07212386 0.00466041 0.00768562 0.01080695 0.01400563 0.04327348
 0.00776014 0.0643398  0.00890812 0.01068665]

train_loss at epoch46: 0.00011800429638242349
train_mses at epoch46: [1.38416841e-03 3.02909652e-04 9.65252021e-05 6.84414979e-05
 2.26740244e-04 2.70958369e-04 6.52083045e-05 3.15992701e-04
 1.26754993e-04 2.35113525e-04]
train_maes at epoch46: [0.03675671 0.0169619  0.00973771 0.00782323 0.01384152 0.01244521
 0.00695213 0.01668042 0.00880823 0.01484784]
test_loss at epoch46: 0.0005092141800560057
test_mses at epoch46: [7.32385565e-03 2.29390035e-05 6.09770642e-05 1.63608812e-04
 2.29500094e-04 2.38883322e-03 9.72169926e-05 3.99786841e-03
 8.73507383e-05 1.92956654e-04]
test_maes at epoch46: [0.07451627 0.00471383 0.00754281 0.0111782  0.01396208 0.04332308
 0.00819576 0.06207884 0.00878186 0.00997865]

train_loss at epoch47: 0.00029189552878960967
train_mses at epoch47: [1.47863461e-02 4.85154540e-04 9.43187121e-05 8.69350019e-05
 1.86252123e-04 9.67115693e-04 4.30461095e-04 4.12329372e-04
 2.35352512e-05 4.30786548e-04]
train_maes at epoch47: [0.11948214 0.02162974 0.00944217 0.00930499 0.01330081 0.03108895
 0.01922526 0.02021171 0.00443341 0.02063075]
test_loss at epoch47: 0.0004743875178974122
test_mses at epoch47: [7.04262816e-03 2.41143411e-05 6.12674407e-05 1.66001469e-04
 2.13853948e-04 2.20042456e-03 9.49023724e-05 3.71059867e-03
 8.33473449e-05 1.70037737e-04]
test_maes at epoch47: [0.07260963 0.00474436 0.00745594 0.0112646  0.01343711 0.04141279
 0.0081481  0.0597254  0.00877087 0.00990417]

train_loss at epoch48: 6.985492655076087e-05
train_mses at epoch48: [1.04396911e-03 9.07891734e-06 2.51440120e-04 4.10642111e-04
 4.71040098e-05 2.52267565e-05 8.28144877e-05 9.29856633e-05
 1.18284616e-06 6.90583105e-05]
train_maes at epoch48: [0.02422431 0.00213369 0.0155997  0.01703589 0.00654727 0.00426492
 0.00885135 0.00964048 0.00091994 0.00820464]
test_loss at epoch48: 0.000445511715952307
test_mses at epoch48: [6.81385396e-03 2.52429854e-05 6.20353066e-05 1.59618038e-04
 2.03673470e-04 2.06256203e-03 9.03541373e-05 3.46023184e-03
 8.07974524e-05 1.51189784e-04]
test_maes at epoch48: [0.07107876 0.00477375 0.00733664 0.01098917 0.01309122 0.0399681
 0.00796611 0.05759443 0.00876071 0.00981167]

train_loss at epoch49: 9.944033809006214e-05
train_mses at epoch49: [3.55131632e-03 2.61628255e-04 1.23713164e-04 1.43817737e-05
 2.85845704e-05 1.25081103e-04 5.76739698e-05 1.49030263e-04
 1.97485282e-04 2.49368632e-04]
train_maes at epoch49: [0.04755855 0.01333024 0.01051899 0.00285408 0.00378925 0.01114325
 0.00752275 0.0108607  0.01383213 0.01368508]
test_loss at epoch49: 0.0004208265745546669
test_mses at epoch49: [6.61456433e-03 2.57439762e-05 6.34102046e-05 1.52477371e-04
 1.98279186e-04 1.99528989e-03 8.73133886e-05 3.19064047e-03
 7.80708902e-05 1.38236632e-04]
test_maes at epoch49: [0.06974006 0.00481422 0.00719351 0.01068607 0.01291625 0.03928254
 0.00787708 0.05523226 0.00870123 0.00968148]

