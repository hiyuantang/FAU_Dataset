train_loss at epoch0: 0.0059942700900137424
train_mses at epoch0: [0.30106687 0.00693721 0.0117827  0.01538893 0.00055825 0.0149277
 0.00097926 0.00611579 0.00487905 0.00269053]
train_maes at epoch0: [0.54869503 0.08255876 0.10815905 0.12079784 0.0236055  0.12052024
 0.02470022 0.05945052 0.06963278 0.05105712]
test_loss at epoch0: 0.004074240569025278
test_mses at epoch0: [2.45789874e-01 2.24140337e-03 6.40615581e-03 8.52567304e-04
 1.30778516e-03 1.74720615e-02 6.11227138e-05 3.56058403e-03
 7.49803662e-03 2.57371158e-04]
test_maes at epoch0: [0.49564691 0.04724792 0.07731479 0.02566812 0.03418285 0.13127358
 0.00765709 0.05955601 0.08385186 0.01198198]

train_loss at epoch1: 0.004429650958627462
train_mses at epoch1: [0.2601388  0.00297826 0.00811552 0.00556232 0.00060846 0.01137512
 0.00032553 0.00855717 0.00487652 0.00141022]
train_maes at epoch1: [0.50988749 0.05356256 0.09005616 0.06870678 0.0238253  0.10613436
 0.01454003 0.08377047 0.06418869 0.03527133]
test_loss at epoch1: 0.003066844306886196
test_mses at epoch1: [1.95968000e-01 1.28723831e-03 3.86907874e-03 1.34574658e-04
 1.11837495e-03 1.43050666e-02 1.10064154e-04 1.98569621e-03
 5.76083675e-03 2.11013669e-04]
test_maes at epoch1: [0.44253658 0.03579293 0.06072696 0.00940602 0.0316111  0.11916473
 0.01029165 0.04454189 0.07387598 0.01074201]

train_loss at epoch2: 0.0023595192469656467
train_mses at epoch2: [1.69415361e-01 5.23798924e-04 3.28869038e-03 3.45425345e-03
 1.61305403e-04 7.60069317e-03 2.18421800e-04 2.08398759e-03
 2.23514858e-03 7.56717466e-04]
train_maes at epoch2: [0.40522154 0.0225613  0.05734228 0.04392923 0.01197833 0.08656247
 0.01460834 0.03701019 0.0472765  0.02724372]
test_loss at epoch2: 0.002383860992267728
test_mses at epoch2: [1.57885361e-01 7.69557048e-04 2.54218727e-03 1.34288799e-05
 9.05662040e-04 1.17248448e-02 1.11360001e-04 1.08642037e-03
 4.50952933e-03 1.66344973e-04]
test_maes at epoch2: [0.39708306 0.02773354 0.04942674 0.00347081 0.02836679 0.10805553
 0.01017285 0.03295419 0.0653507  0.01034596]

train_loss at epoch3: 0.0022102762013673782
train_mses at epoch3: [0.15588428 0.00108459 0.0014714  0.00205004 0.0004357  0.00703448
 0.00059936 0.00162982 0.00420246 0.00080463]
train_maes at epoch3: [0.3927806  0.03244176 0.03796799 0.03917206 0.02072108 0.08318892
 0.02421123 0.03622971 0.05597829 0.02720525]
test_loss at epoch3: 0.0018466295441612601
test_mses at epoch3: [1.25434404e-01 4.58827751e-04 1.66547486e-03 9.48773078e-05
 6.76475094e-04 9.45831082e-03 1.07575134e-04 5.76223043e-04
 3.43863195e-03 1.27735399e-04]
test_maes at epoch3: [0.35360575 0.02141535 0.03993572 0.0096933  0.02429873 0.09704617
 0.00982089 0.02397267 0.05696215 0.00938749]

train_loss at epoch4: 0.0008772779256105423
train_mses at epoch4: [0.05851748 0.0006619  0.00018184 0.00082496 0.00020063 0.00420245
 0.00034405 0.00049572 0.00084628 0.00023503]
train_maes at epoch4: [0.23025793 0.01890565 0.012999   0.02823025 0.01376727 0.06464935
 0.01798203 0.02224113 0.02079673 0.01136909]
test_loss at epoch4: 0.0013823098270222545
test_mses at epoch4: [9.58951192e-02 2.37260708e-04 9.83507072e-04 3.10848924e-04
 4.70698557e-04 7.17529020e-03 9.69244377e-05 2.72627246e-04
 2.59776400e-03 8.89124970e-05]
test_maes at epoch4: [0.30849829 0.01536388 0.03033279 0.01758473 0.01981215 0.08441795
 0.00898153 0.01641163 0.04927852 0.00769848]

train_loss at epoch5: 0.0006599374464713037
train_mses at epoch5: [4.17759051e-02 4.83162004e-04 1.13887187e-03 7.78066863e-04
 1.04711100e-04 1.10093951e-03 1.88812875e-05 6.67023308e-04
 6.41574845e-04 1.29861316e-03]
train_maes at epoch5: [0.20039628 0.02173464 0.03350321 0.02104424 0.00977985 0.0306228
 0.00412585 0.02435097 0.01837845 0.03565076]
test_loss at epoch5: 0.0009746603900566697
test_mses at epoch5: [6.93792144e-02 8.51374934e-05 4.57860986e-04 5.41913862e-04
 3.33151383e-04 4.94277146e-03 8.66902703e-05 8.45966730e-05
 1.86621553e-03 5.54150611e-05]
test_maes at epoch5: [0.26121986 0.00903884 0.01981766 0.0231494  0.01600911 0.06985371
 0.0079653  0.00898069 0.04124819 0.00532896]

train_loss at epoch6: 0.00030606650398112833
train_mses at epoch6: [8.55390794e-03 2.78633446e-04 1.59781607e-03 3.86787761e-05
 1.15284069e-04 1.55268944e-04 3.50967993e-04 6.92471164e-04
 1.05716796e-04 6.12108931e-04]
train_maes at epoch6: [0.08760731 0.01510222 0.03837285 0.00612521 0.00781079 0.01235135
 0.0182772  0.02240942 0.01027931 0.02453247]
test_loss at epoch6: 0.0006937579601071775
test_mses at epoch6: [4.88921088e-02 2.04133476e-05 1.86227445e-04 7.86584564e-04
 2.47808503e-04 3.31307383e-03 9.04587210e-05 9.17183684e-06
 1.37548808e-03 3.61220729e-05]
test_maes at epoch6: [0.21764183 0.0038008  0.01082798 0.02786007 0.01311768 0.05686734
 0.00796691 0.00224848 0.03488808 0.00488999]

train_loss at epoch7: 0.0002928243193309754
train_mses at epoch7: [1.72242219e-02 1.75991660e-04 5.38444437e-04 3.45270131e-05
 2.80465988e-05 5.39040673e-04 1.71526491e-04 9.98459734e-04
 2.07162997e-04 2.00127562e-04]
train_maes at epoch7: [0.12573351 0.01164326 0.017026   0.00587549 0.00529327 0.01830809
 0.01104423 0.02631823 0.01193367 0.01203452]
test_loss at epoch7: 0.000491970160510391
test_mses at epoch7: [3.23840067e-02 1.05001430e-05 8.58036457e-05 1.06328260e-03
 1.73883953e-04 2.02858126e-03 1.00012155e-04 9.45483612e-06
 1.02427734e-03 2.87362661e-05]
test_maes at epoch7: [0.17468153 0.00301724 0.008795   0.03238804 0.00991885 0.04390941
 0.00828727 0.0022347  0.02941415 0.00471067]

train_loss at epoch8: 0.0005308053805492818
train_mses at epoch8: [8.32157584e-04 1.58023679e-03 5.94755535e-04 1.88665941e-03
 2.78488215e-04 4.64302291e-05 2.85239332e-04 1.40755211e-03
 6.94355220e-04 1.43885202e-03]
train_maes at epoch8: [0.02876446 0.03481296 0.02303448 0.03980397 0.01485033 0.00554326
 0.01307878 0.03264229 0.02542525 0.03783861]
test_loss at epoch8: 0.00037814860115759075
test_mses at epoch8: [2.27063973e-02 2.41735564e-05 9.00341647e-05 1.17510519e-03
 1.40741656e-04 1.27598888e-03 1.33880557e-04 2.24587538e-05
 7.93467805e-04 3.52997335e-05]
test_maes at epoch8: [0.14313693 0.00357575 0.00919155 0.03402296 0.00866564 0.03394386
 0.01001736 0.00426321 0.02508472 0.00473998]

train_loss at epoch9: 0.000973119807895273
train_mses at epoch9: [0.00416525 0.00014196 0.00501884 0.00010778 0.00028778 0.00489348
 0.00090089 0.00170527 0.00058007 0.00116215]
train_maes at epoch9: [0.04747546 0.00900652 0.07066504 0.00871246 0.01499816 0.06806803
 0.02770726 0.03908586 0.02022188 0.02822878]
test_loss at epoch9: 0.0003557387681212276
test_mses at epoch9: [1.99280609e-02 3.21189998e-05 8.77675685e-05 1.18330912e-03
 1.32096419e-04 1.21478510e-03 2.02534633e-04 1.96616898e-05
 6.88905747e-04 5.11393940e-05]
test_maes at epoch9: [0.13251348 0.00407287 0.00919496 0.03409844 0.0083488  0.03288977
 0.01305192 0.00396706 0.0231904  0.00545573]

train_loss at epoch10: 0.0009026864427141845
train_mses at epoch10: [1.45450742e-02 5.88710474e-04 1.47785472e-03 8.24316240e-04
 1.12982835e-05 6.73417376e-03 6.64818579e-04 7.70234985e-05
 2.24092431e-03 6.49392826e-05]
train_maes at epoch10: [0.11341204 0.02256518 0.03021725 0.02649791 0.00303947 0.06169376
 0.02107371 0.00870059 0.04061456 0.00785868]
test_loss at epoch10: 0.00037495369906537235
test_mses at epoch10: [2.05322066e-02 2.48768264e-05 7.85491667e-05 1.09917916e-03
 1.37675086e-04 1.48954496e-03 2.72927723e-04 1.46653784e-05
 6.70154159e-04 6.59807762e-05]
test_maes at epoch10: [0.13501808 0.00425947 0.00871645 0.0328024  0.00866877 0.03695397
 0.01558858 0.0033408  0.02324336 0.00686147]

train_loss at epoch11: 0.0003198272024746984
train_mses at epoch11: [4.44583432e-03 1.35595008e-04 9.04945822e-04 2.02156535e-03
 1.78612699e-04 2.10807078e-04 1.33946649e-05 7.33554179e-04
 1.33058593e-04 2.31603571e-04]
train_maes at epoch11: [0.0588586  0.01055611 0.02316431 0.04422609 0.01256423 0.01108277
 0.00329724 0.02371551 0.00985723 0.01503389]
test_loss at epoch11: 0.00040831053047440946
test_mses at epoch11: [2.25590219e-02 1.91381612e-05 9.76866835e-05 9.20417497e-04
 1.51749489e-04 1.88471656e-03 3.55760537e-04 6.35806438e-06
 6.59940422e-04 8.10556721e-05]
test_maes at epoch11: [0.14287151 0.00428427 0.00812652 0.02994768 0.00987898 0.04210802
 0.01810859 0.00186062 0.02345494 0.00804778]

train_loss at epoch12: 0.0002771050203591585
train_mses at epoch12: [4.99187638e-03 7.28495333e-04 6.51684777e-04 8.82076736e-04
 3.25976472e-05 7.74008740e-04 1.06032240e-04 4.35197653e-04
 2.22970752e-04 9.21409832e-06]
train_maes at epoch12: [0.06902629 0.0237619  0.01838527 0.02412053 0.00566661 0.0277651
 0.00792332 0.01980225 0.01489547 0.00293398]
test_loss at epoch12: 0.0004522496892604977
test_mses at epoch12: [2.53505593e-02 1.98180041e-05 1.52771542e-04 7.31582894e-04
 1.68565518e-04 2.33532225e-03 4.34060669e-04 2.46630949e-06
 6.51968348e-04 9.42049435e-05]
test_maes at epoch12: [0.15268874 0.00423815 0.00974032 0.02660109 0.01100484 0.0472372
 0.02019027 0.00157004 0.02364358 0.00894032]

train_loss at epoch13: 0.00044228453771211207
train_mses at epoch13: [2.02700960e-03 2.72195276e-06 8.59211293e-06 1.01669033e-03
 2.71847380e-05 2.39698318e-03 8.54086931e-04 9.21085480e-04
 1.35973287e-03 1.25668988e-04]
train_maes at epoch13: [0.04415707 0.0013971  0.00290144 0.02434939 0.00463889 0.04597566
 0.02305437 0.02199181 0.03687455 0.00974254]
test_loss at epoch13: 0.0005082625430077314
test_mses at epoch13: [2.88041395e-02 3.01640382e-05 2.38722208e-04 5.49783136e-04
 1.94663316e-04 2.88490990e-03 4.85777060e-04 6.90630382e-06
 6.30873128e-04 1.06898812e-04]
test_maes at epoch13: [0.1638633  0.00420567 0.01370838 0.02293054 0.01238291 0.05279216
 0.02142935 0.00216935 0.02351486 0.00971321]

train_loss at epoch14: 0.00028332299552857876
train_mses at epoch14: [2.72985247e-04 3.20627029e-04 1.53965683e-03 1.30113827e-04
 2.23366633e-04 8.23079027e-05 2.62196948e-04 7.98502285e-04
 7.50547001e-04 2.92944655e-04]
train_maes at epoch14: [0.0164625  0.01631805 0.03921332 0.01140585 0.01476993 0.00864613
 0.01400805 0.02108648 0.02654511 0.01490989]
test_loss at epoch14: 0.0005833075847476721
test_mses at epoch14: [3.30773042e-02 5.10676606e-05 3.75638504e-04 3.97223511e-04
 2.27514361e-04 3.52346858e-03 5.31631102e-04 2.25517241e-05
 6.31604114e-04 1.23275483e-04]
test_maes at epoch14: [0.1767339  0.00586492 0.01822699 0.01933954 0.0138323  0.05859197
 0.02248327 0.00454055 0.02377164 0.01056904]

train_loss at epoch15: 0.0003196083998773247
train_mses at epoch15: [1.52436271e-03 1.85735186e-04 5.63602693e-05 8.65398413e-04
 2.63969025e-04 8.36233370e-04 5.65833914e-04 1.64643510e-04
 1.05465919e-03 8.52184842e-04]
train_maes at epoch15: [0.0382255  0.01120802 0.00718833 0.02825209 0.01389905 0.02678157
 0.01739051 0.0092107  0.03054425 0.02688712]
test_loss at epoch15: 0.0006667912821285427
test_mses at epoch15: [3.77753698e-02 8.26562970e-05 5.30568050e-04 2.63341522e-04
 2.75198181e-04 4.16164915e-03 5.56636836e-04 4.78347310e-05
 6.79329079e-04 1.32399009e-04]
test_maes at epoch15: [0.18983075 0.00820465 0.02219436 0.01554156 0.01559122 0.06384801
 0.02303829 0.00679351 0.02493299 0.0110042 ]

train_loss at epoch16: 0.0003725251299329102
train_mses at epoch16: [2.34431104e-03 4.28619373e-04 7.12511768e-04 3.21487568e-04
 2.54520733e-04 2.52683032e-03 7.14543974e-04 5.77613950e-04
 3.37308540e-05 2.19102633e-05]
train_maes at epoch16: [0.04716016 0.01761285 0.02346897 0.01779731 0.01332123 0.0496038
 0.02673083 0.02249261 0.00539701 0.00359633]
test_loss at epoch16: 0.0007176347426138818
test_mses at epoch16: [4.08422768e-02 1.19870401e-04 6.38361675e-04 1.66969599e-04
 3.01141441e-04 4.51012584e-03 5.47720953e-04 8.42296268e-05
 7.14526788e-04 1.41592575e-04]
test_maes at epoch16: [0.19792545 0.01028894 0.02457279 0.0121272  0.01648189 0.06654298
 0.02283341 0.00910788 0.02574065 0.01140398]

train_loss at epoch17: 0.00021997718431521207
train_mses at epoch17: [3.11648477e-03 1.30267977e-04 6.58340818e-04 1.99522180e-04
 3.46267955e-05 4.87401064e-04 6.93303043e-04 8.03369374e-05
 4.93740993e-04 3.55259254e-04]
train_maes at epoch17: [0.05404243 0.01108819 0.02472986 0.01393298 0.00572207 0.02204435
 0.02056601 0.00895633 0.01971484 0.01816597]
test_loss at epoch17: 0.0007793297991156578
test_mses at epoch17: [0.04438594 0.00015744 0.00077527 0.00010079 0.00032312 0.00490424
 0.00053042 0.00012419 0.00076897 0.00015803]
test_maes at epoch17: [0.20686556 0.01203021 0.02728207 0.00908663 0.01720167 0.06947008
 0.02243652 0.01109993 0.02686892 0.0120936 ]

train_loss at epoch18: 0.00035242928424850106
train_mses at epoch18: [1.10712134e-02 5.91389223e-05 3.05943276e-04 2.60376306e-04
 7.62123509e-05 2.38173420e-03 6.73921127e-04 2.11163324e-04
 2.56983094e-04 2.00062056e-04]
train_maes at epoch18: [0.1027379  0.00753922 0.01612175 0.01338314 0.00783952 0.04800785
 0.02243207 0.0138022  0.01537261 0.01379693]
test_loss at epoch18: 0.0008022564579732716
test_mses at epoch18: [4.55748601e-02 1.84082951e-04 8.51275276e-04 6.41731320e-05
 3.31334532e-04 5.01601242e-03 4.94157046e-04 1.59102770e-04
 8.11193059e-04 1.73256403e-04]
test_maes at epoch18: [0.20977664 0.01311891 0.02867474 0.00685427 0.01747813 0.07027698
 0.02159641 0.01258663 0.02769535 0.01268953]

train_loss at epoch19: 0.0002477879752404988
train_mses at epoch19: [4.82836613e-03 2.67730925e-04 6.82643302e-05 6.59319388e-04
 1.40408949e-04 1.19514087e-03 2.64242891e-04 1.75019245e-04
 4.82547020e-04 1.47492740e-04]
train_maes at epoch19: [0.05670442 0.01393791 0.00679641 0.02331935 0.01016801 0.03456585
 0.01487861 0.01312216 0.02089477 0.01202773]
test_loss at epoch19: 0.0008018572116270661
test_mses at epoch19: [4.55599395e-02 2.02378422e-04 9.00822177e-04 4.15675595e-05
 3.28725603e-04 4.95788467e-03 4.53821507e-04 1.90693644e-04
 8.13241669e-04 1.90670482e-04]
test_maes at epoch19: [0.20974448 0.01380966 0.02954136 0.00503751 0.01742379 0.06985728
 0.02061702 0.01379228 0.02775708 0.01333431]

train_loss at epoch20: 0.00022488940157927573
train_mses at epoch20: [8.54831811e-03 3.22214834e-04 1.73997836e-04 7.69574522e-05
 5.44736966e-05 8.59990622e-04 1.79413235e-05 4.46876637e-04
 6.10589118e-04 1.16058584e-04]
train_maes at epoch20: [0.08008824 0.01635392 0.01317478 0.00706894 0.0068943  0.02884984
 0.00367839 0.01937468 0.02166919 0.01049307]
test_loss at epoch20: 0.0007748973439447582
test_mses at epoch20: [4.41184819e-02 2.05615059e-04 8.97698530e-04 2.56437929e-05
 3.14329644e-04 4.71008333e-03 4.16849857e-04 2.30382886e-04
 7.88073452e-04 2.10648713e-04]
test_maes at epoch20: [0.20621692 0.01393164 0.02949115 0.00389443 0.01700582 0.06804084
 0.01966979 0.01516943 0.02731689 0.01402917]

train_loss at epoch21: 0.0002828769793268293
train_mses at epoch21: [0.00398182 0.0001143  0.00017905 0.00084334 0.00018456 0.00101753
 0.00050671 0.00032435 0.00017039 0.00069087]
train_maes at epoch21: [0.0630907  0.00976279 0.01040836 0.0289855  0.01130164 0.02971166
 0.02251022 0.01799468 0.01270656 0.02061345]
test_loss at epoch21: 0.0007349624065682292
test_mses at epoch21: [4.16922533e-02 2.02634739e-04 8.85538328e-04 2.08538528e-05
 2.88718002e-04 4.36327095e-03 3.63100364e-04 2.67794939e-04
 7.77549523e-04 2.42817492e-04]
test_maes at epoch21: [0.200123   0.01381842 0.02927503 0.00385261 0.01621591 0.06540552
 0.01820329 0.01636118 0.02712338 0.01510987]

train_loss at epoch22: 0.00019198407244402915
train_mses at epoch22: [1.70181530e-03 1.18773795e-04 1.19088851e-05 1.85064418e-05
 1.60968692e-05 6.96126382e-05 2.24744749e-04 1.39569122e-04
 1.95778016e-03 2.76565710e-04]
train_maes at epoch22: [0.03909658 0.0081673  0.00299004 0.00368917 0.00343612 0.00803065
 0.01457851 0.00994162 0.04422487 0.01207947]
test_loss at epoch22: 0.0006894826074130833
test_mses at epoch22: [3.89624307e-02 1.92747476e-04 8.61992202e-04 1.73715151e-05
 2.62456235e-04 4.00788108e-03 3.03810516e-04 2.96575240e-04
 7.59507919e-04 2.65897834e-04]
test_maes at epoch22: [0.19303934 0.01345244 0.02885207 0.00377355 0.01536389 0.06258489
 0.01642988 0.01722044 0.02676748 0.01583833]

train_loss at epoch23: 0.0002703471982385963
train_mses at epoch23: [1.47313987e-02 1.74849970e-04 1.83885648e-04 1.47540445e-03
 8.68661256e-05 2.52810266e-04 1.33073884e-04 3.08011839e-04
 1.52225548e-04 1.84337935e-05]
train_maes at epoch23: [0.096233   0.012903   0.01289432 0.02905837 0.00931611 0.01589992
 0.00849311 0.01748953 0.01233797 0.00398856]
test_loss at epoch23: 0.0006371684721671045
test_mses at epoch23: [3.55587754e-02 1.82605762e-04 8.20233948e-04 1.78652257e-05
 2.29721905e-04 3.61515196e-03 2.44318528e-04 3.11075153e-04
 7.70516276e-04 2.91731654e-04]
test_maes at epoch23: [0.18379469 0.01306444 0.02809199 0.00379106 0.01422707 0.05930175
 0.01442572 0.01763723 0.02695008 0.01662004]

train_loss at epoch24: 0.00021208352700341493
train_mses at epoch24: [1.29161468e-03 1.06919212e-04 2.13472736e-05 8.05511025e-04
 6.89640781e-05 5.88156205e-04 2.57602201e-04 2.21168666e-05
 4.94312000e-04 8.22741945e-04]
train_maes at epoch24: [0.02883393 0.01027907 0.00457056 0.02418967 0.00819271 0.01947691
 0.01591879 0.00463549 0.0222006  0.02719709]
test_loss at epoch24: 0.000607838504947722
test_mses at epoch24: [3.31557107e-02 1.82486885e-04 8.03131874e-04 2.15685812e-05
 2.10900065e-04 3.39394429e-03 2.09369004e-04 3.22839622e-04
 8.21392149e-04 2.93981282e-04]
test_maes at epoch24: [0.17698534 0.01306543 0.02776724 0.0038598  0.01353829 0.05736863
 0.01311774 0.01796769 0.02788074 0.01670626]

train_loss at epoch25: 0.00022863507911097258
train_mses at epoch25: [8.49027052e-03 1.10332108e-04 1.80705035e-04 1.20667805e-03
 6.21874866e-05 1.85858391e-04 3.74424413e-05 3.00674294e-04
 1.82390787e-04 4.77026337e-04]
train_maes at epoch25: [0.07734405 0.00770943 0.01236242 0.03252849 0.00568468 0.0117698
 0.00522608 0.01708946 0.01332048 0.01938946]
test_loss at epoch25: 0.0005872446345165372
test_mses at epoch25: [3.09093387e-02 1.80281569e-04 8.07460819e-04 3.21735382e-05
 1.98768350e-04 3.25232017e-03 1.77556741e-04 3.20427239e-04
 8.78250699e-04 3.09968214e-04]
test_maes at epoch25: [0.17032221 0.01298621 0.02782815 0.00401277 0.013077   0.05608153
 0.01178713 0.01790013 0.0288854  0.01719929]

train_loss at epoch26: 0.00029158807592466474
train_mses at epoch26: [0.0077828  0.00041471 0.00036249 0.00024464 0.00051415 0.00042304
 0.00074443 0.0002351  0.00060994 0.00024751]
train_maes at epoch26: [0.08661339 0.01717756 0.01872257 0.01411078 0.02082237 0.01680373
 0.02016055 0.01291713 0.02105158 0.01218562]
test_loss at epoch26: 0.0005808102432638407
test_mses at epoch26: [2.95653326e-02 1.71672675e-04 8.33730205e-04 5.05233296e-05
 1.98889591e-04 3.17135809e-03 1.65935225e-04 3.12299966e-04
 9.71504909e-04 3.12006853e-04]
test_maes at epoch26: [0.16626847 0.01264655 0.02829893 0.0057092  0.01311035 0.05535072
 0.01129504 0.01767136 0.03049268 0.01728501]

train_loss at epoch27: 0.00024831193150021136
train_mses at epoch27: [3.59324507e-03 4.63558901e-04 5.17184339e-04 2.60202512e-04
 1.88433511e-05 1.77383755e-03 1.28122565e-04 2.06421733e-04
 1.52607039e-04 8.19302367e-06]
train_maes at epoch27: [0.04660068 0.01917124 0.02273288 0.01472846 0.0043338  0.03829595
 0.01131854 0.01400757 0.0106264  0.00211826]
test_loss at epoch27: 0.0005507030873559415
test_mses at epoch27: [2.71384022e-02 1.51921364e-04 8.07729538e-04 7.32915360e-05
 1.89987379e-04 2.92042013e-03 1.50393667e-04 3.03175819e-04
 1.03933281e-03 3.18249658e-04]
test_maes at epoch27: [0.15868232 0.01183351 0.0278199  0.00734317 0.01277343 0.05301048
 0.01058297 0.01741095 0.03159702 0.01747939]

train_loss at epoch28: 0.00018630838894750923
train_mses at epoch28: [2.84656020e-03 1.02339006e-04 5.47064125e-04 1.90453479e-04
 1.56723847e-05 8.98820417e-05 8.13161254e-05 1.07009558e-03
 1.49236451e-04 3.87025257e-04]
train_maes at epoch28: [0.05298123 0.00752235 0.02002664 0.01229691 0.00392894 0.0068721
 0.00835459 0.02653379 0.01209319 0.01490037]
test_loss at epoch28: 0.0005460440297611058
test_mses at epoch28: [0.02618475 0.00014349 0.00083411 0.00010306 0.00018674 0.00283182
 0.00014408 0.00028308 0.00114033 0.00030812]
test_maes at epoch28: [0.15564461 0.01147574 0.02828787 0.00905906 0.01267006 0.05217086
 0.01030975 0.01682432 0.03318054 0.01721148]

train_loss at epoch29: 0.00019242877897340804
train_mses at epoch29: [4.04445038e-03 3.56261125e-05 5.07786008e-04 5.18019401e-05
 2.07802333e-04 1.13547135e-03 1.23404273e-04 9.91510500e-05
 1.42255219e-04 3.08435470e-04]
train_maes at epoch29: [0.05143538 0.0059144  0.02173139 0.0054057  0.01370111 0.03337681
 0.01101656 0.00995389 0.00866059 0.01264827]
test_loss at epoch29: 0.0005232617841102183
test_mses at epoch29: [0.02434782 0.00012936 0.00081081 0.0001352  0.00018155 0.00260886
 0.00013425 0.00026237 0.00124299 0.00029287]
test_maes at epoch29: [0.14951359 0.01083978 0.02785567 0.01060517 0.01246741 0.04996085
 0.0098302  0.01619733 0.03470563 0.01677725]

train_loss at epoch30: 0.0001865166996140033
train_mses at epoch30: [3.72260538e-03 7.06309430e-05 1.49853112e-04 9.34130886e-04
 6.86110636e-05 4.96587311e-04 8.83082057e-05 1.39615846e-04
 5.80506903e-04 2.25433527e-05]
train_maes at epoch30: [0.06039011 0.00641505 0.01125236 0.03003966 0.00820149 0.01798967
 0.00696857 0.01052138 0.02408409 0.00464664]
test_loss at epoch30: 0.0005179455620236695
test_mses at epoch30: [0.02386042 0.00012467 0.00080519 0.00014723 0.00018737 0.00252145
 0.00012698 0.00024264 0.00133052 0.00027673]
test_maes at epoch30: [0.14787097 0.01063453 0.02774773 0.01111774 0.01271917 0.04906815
 0.00946746 0.01557672 0.0359615  0.01630482]

train_loss at epoch31: 0.00020207626221235842
train_mses at epoch31: [2.06624687e-03 6.32786282e-05 5.88389200e-04 6.88577192e-04
 1.68830339e-04 3.69531481e-04 3.76213051e-05 3.69884591e-04
 5.75908843e-04 9.36381768e-05]
train_maes at epoch31: [0.04013918 0.00591064 0.02250432 0.02026619 0.01186081 0.01832956
 0.00607591 0.01788342 0.01873075 0.006894  ]
test_loss at epoch31: 0.0004963692626915872
test_mses at epoch31: [0.02286749 0.00011586 0.00075962 0.00014185 0.00019732 0.00235277
 0.00012165 0.00022336 0.00135173 0.00025844]
test_maes at epoch31: [0.14445987 0.01022742 0.02689167 0.01089461 0.01313068 0.04728526
 0.00918539 0.01494512 0.03625109 0.01574696]

train_loss at epoch32: 0.00011323435319354758
train_mses at epoch32: [4.49931509e-03 2.47007354e-04 3.61513742e-05 9.28783475e-05
 1.02485911e-04 4.85145763e-04 1.35111217e-04 1.27384357e-04
 1.31129941e-05 9.06231999e-05]
train_maes at epoch32: [0.06405902 0.01212688 0.00591097 0.00936282 0.00976695 0.0207307
 0.01104608 0.01100396 0.00266265 0.00929332]
test_loss at epoch32: 0.0004925638786517084
test_mses at epoch32: [0.02298233 0.00011593 0.00074473 0.00013418 0.00021207 0.00230011
 0.00012207 0.00021493 0.0013693  0.00023861]
test_maes at epoch32: [0.14492401 0.01026375 0.02660338 0.01055567 0.01371451 0.04670917
 0.00924924 0.01466039 0.03649235 0.01511993]

train_loss at epoch33: 0.00013265041343402117
train_mses at epoch33: [2.78437101e-03 5.00812358e-05 8.29696017e-05 2.31802211e-04
 1.03679130e-05 1.62252932e-04 2.08056929e-04 4.70708419e-04
 4.79986029e-04 1.04526389e-04]
train_maes at epoch33: [0.05136982 0.00705036 0.00870242 0.01089295 0.00321104 0.0105677
 0.01440295 0.01972294 0.01816374 0.00984475]
test_loss at epoch33: 0.0004994068294763565
test_mses at epoch33: [0.02384791 0.00011945 0.00075131 0.00012942 0.00022756 0.00234296
 0.00012446 0.0002039  0.00136157 0.0002137 ]
test_maes at epoch33: [0.14801744 0.01046229 0.02672618 0.01033542 0.01430203 0.04717654
 0.00942001 0.01427921 0.03639557 0.01429584]

train_loss at epoch34: 0.00026509034796617925
train_mses at epoch34: [4.48540973e-03 3.83719718e-05 3.27660967e-04 2.67463283e-04
 2.67454118e-04 2.24060628e-04 1.18171214e-04 3.43570152e-04
 1.08237368e-03 1.03488249e-03]
train_maes at epoch34: [0.06295261 0.00609887 0.01632716 0.01560755 0.01359018 0.01218176
 0.01046342 0.01818472 0.03264698 0.02758941]
test_loss at epoch34: 0.0004974409239366651
test_mses at epoch34: [0.02467634 0.00012472 0.0007479  0.00012133 0.00023701 0.00236935
 0.0001218  0.00018432 0.00128015 0.00017611]
test_maes at epoch34: [0.15098272 0.01074383 0.02666911 0.00998022 0.01466663 0.04747409
 0.00930826 0.01357654 0.03525297 0.01295235]

train_loss at epoch35: 0.0002827287244144827
train_mses at epoch35: [1.28311286e-02 2.68301207e-06 3.64038937e-04 4.65064203e-04
 2.55523613e-04 8.36556249e-04 1.09676298e-04 3.68847225e-04
 4.43011914e-04 3.19194771e-04]
train_maes at epoch35: [0.09693538 0.00121139 0.01373709 0.01733845 0.01206239 0.02851404
 0.00953182 0.01898654 0.01592059 0.01784365]
test_loss at epoch35: 0.0005037756636738777
test_mses at epoch35: [0.02629263 0.00013271 0.00074552 0.00010243 0.00025798 0.0024669
 0.00011906 0.00016945 0.00117278 0.00013703]
test_maes at epoch35: [0.15636502 0.01112925 0.02662621 0.009046   0.01539572 0.04849407
 0.00917908 0.01301681 0.03369447 0.01138617]

train_loss at epoch36: 0.00026136459200643003
train_mses at epoch36: [6.37552285e-03 1.09211741e-04 2.71882705e-04 3.76041521e-05
 4.44512235e-05 2.20837019e-04 5.59170622e-04 4.33594382e-04
 9.85997815e-05 1.68586007e-03]
train_maes at epoch36: [0.07199264 0.00929527 0.01613757 0.00492946 0.00616239 0.01407987
 0.02090633 0.01569377 0.00919581 0.03233402]
test_loss at epoch36: 0.0005222113686613739
test_mses at epoch36: [2.85671135e-02 1.50782902e-04 7.46496497e-04 8.56975010e-05
 2.77113470e-04 2.62316524e-03 1.26377201e-04 1.67012847e-04
 1.07187570e-03 1.21273554e-04]
test_maes at epoch36: [0.1635545  0.01193272 0.02664026 0.00812378 0.01602913 0.05007205
 0.00959254 0.01292227 0.03215905 0.01069986]

train_loss at epoch37: 0.00021196035959292203
train_mses at epoch37: [7.48771462e-03 2.77629337e-04 5.65405326e-04 5.66743113e-04
 2.31026385e-05 5.18331159e-04 1.14380837e-04 2.88186584e-05
 1.21581798e-04 3.64665726e-04]
train_maes at epoch37: [0.0799754  0.01639235 0.02147216 0.01935592 0.00478556 0.01922134
 0.01054643 0.00509106 0.00854018 0.0173755 ]
test_loss at epoch37: 0.0005696718581020832
test_mses at epoch37: [3.25827108e-02 1.78832118e-04 8.00861989e-04 6.53482625e-05
 3.02556697e-04 2.96234043e-03 1.46000788e-04 1.69128786e-04
 9.84534591e-04 1.09613610e-04]
test_maes at epoch37: [0.17560063 0.01308181 0.02766939 0.00680292 0.01683808 0.05338043
 0.01062024 0.01300267 0.0307855  0.01016728]

train_loss at epoch38: 0.00019218040688429028
train_mses at epoch38: [2.66848724e-03 3.42474195e-04 1.36301489e-04 1.48968726e-04
 2.67032374e-04 6.56122482e-05 3.34015818e-05 4.98996559e-04
 7.02608967e-04 5.46828194e-04]
train_maes at epoch38: [0.04897234 0.0181366  0.00988705 0.00884429 0.01536025 0.0079485
 0.00485831 0.01800354 0.02480385 0.02169483]
test_loss at epoch38: 0.0006082642357796431
test_mses at epoch38: [3.58639345e-02 2.05857249e-04 8.35637264e-04 5.29788696e-05
 3.20200798e-04 3.23705342e-03 1.61543673e-04 1.63829080e-04
 9.22175478e-04 1.02515292e-04]
test_maes at epoch38: [0.18483284 0.01409499 0.02830695 0.00587068 0.0173753  0.05590715
 0.01135962 0.01279548 0.02975443 0.00983527]

train_loss at epoch39: 0.0001617135276319459
train_mses at epoch39: [3.71177896e-03 1.01092388e-04 4.01879441e-04 2.99289644e-05
 3.23613395e-04 2.14178273e-04 4.48036732e-04 2.14337089e-04
 1.24265782e-04 3.06963413e-04]
train_maes at epoch39: [0.06051716 0.0097356  0.01948603 0.00511414 0.0129654  0.01386547
 0.01807634 0.01325352 0.0093624  0.01646349]
test_loss at epoch39: 0.0006297898362390697
test_mses at epoch39: [3.80486516e-02 2.26635414e-04 8.34798460e-04 4.28704577e-05
 3.22453177e-04 3.39791769e-03 1.81697302e-04 1.62480001e-04
 8.56652821e-04 9.92720115e-05]
test_maes at epoch39: [0.19071621 0.01482831 0.02829355 0.00500147 0.0174497  0.05731986
 0.01224989 0.01274162 0.02862125 0.00968627]

train_loss at epoch40: 0.00028277604724280536
train_mses at epoch40: [1.40066680e-02 7.21702108e-05 2.82641914e-04 8.21203498e-05
 3.78301245e-04 1.77198888e-03 3.35000418e-04 9.95394124e-05
 2.59062713e-06 2.61840156e-05]
train_maes at epoch40: [0.11242735 0.00712886 0.01582885 0.00801673 0.0191301  0.04158729
 0.0162504  0.00956856 0.0012886  0.0039259 ]
test_loss at epoch40: 0.0006165315280668437
test_mses at epoch40: [3.81300997e-02 2.37556907e-04 7.81998976e-04 3.66914476e-05
 3.04252124e-04 3.32048854e-03 1.88743683e-04 1.55567864e-04
 7.87972752e-04 9.63891898e-05]
test_maes at epoch40: [0.19085988 0.01520553 0.02731902 0.00441181 0.0169115  0.05658867
 0.01253699 0.01246649 0.02735767 0.00954436]

train_loss at epoch41: 0.00023867627896834165
train_mses at epoch41: [5.86338013e-03 1.43191496e-04 5.38096070e-04 4.50528782e-04
 7.57580342e-04 3.33135563e-04 4.32987898e-05 3.76704124e-05
 6.19006089e-04 2.34213358e-04]
train_maes at epoch41: [0.07465269 0.01143688 0.02016796 0.0207511  0.02724272 0.01341512
 0.00527557 0.00519047 0.02456982 0.01519571]
test_loss at epoch41: 0.0005877026706002653
test_mses at epoch41: [3.71647442e-02 2.41823495e-04 7.03882388e-04 3.26227361e-05
 2.68889772e-04 3.15005690e-03 1.93689339e-04 1.50194125e-04
 7.17430462e-04 9.48950259e-05]
test_maes at epoch41: [0.18820199 0.01535632 0.02581311 0.00412438 0.01581051 0.05499809
 0.01271695 0.01224787 0.02600046 0.00946386]

train_loss at epoch42: 0.0001230361231137067
train_mses at epoch42: [6.76324815e-04 1.47685404e-04 2.37332732e-05 7.13809483e-04
 1.85727432e-04 2.51089615e-04 6.48641111e-05 1.66227499e-04
 2.12002038e-04 9.12530254e-05]
train_maes at epoch42: [0.01983914 0.01185796 0.00476644 0.02486535 0.01077287 0.01254581
 0.00792125 0.01282153 0.01100707 0.00758898]
test_loss at epoch42: 0.0005778912454843521
test_mses at epoch42: [3.70899633e-02 2.55978553e-04 6.56941099e-04 3.12418555e-05
 2.49284432e-04 3.09177295e-03 2.01056737e-04 1.45326618e-04
 6.79780598e-04 9.61006684e-05]
test_maes at epoch42: [0.18795742 0.01582235 0.02486601 0.00414935 0.01516716 0.05443282
 0.01300744 0.01204642 0.02525121 0.00952555]

train_loss at epoch43: 0.00020607319311238825
train_mses at epoch43: [1.66350823e-02 8.62379904e-05 2.57060859e-04 3.44602596e-04
 6.92088582e-05 4.04930506e-04 3.75784601e-05 1.59573172e-04
 8.12592059e-05 1.54922086e-04]
train_maes at epoch43: [0.12690565 0.0074923  0.01468281 0.01551033 0.00757063 0.01742622
 0.00594582 0.01108684 0.00738553 0.01033566]
test_loss at epoch43: 0.0005533789517357945
test_mses at epoch43: [3.57539359e-02 2.66312527e-04 5.95507809e-04 3.40795957e-05
 2.23650811e-04 2.94682045e-03 2.00438184e-04 1.40802853e-04
 6.51532278e-04 9.58058482e-05]
test_maes at epoch43: [0.18427603 0.01615884 0.0235709  0.00424546 0.01427929 0.05304565
 0.01295514 0.01185631 0.02466071 0.00950864]

train_loss at epoch44: 0.00012430529750417918
train_mses at epoch44: [3.93813541e-03 2.82280497e-04 1.83625951e-04 7.77353217e-05
 4.15087016e-05 9.11031999e-05 3.34513612e-04 1.90449502e-04
 2.89751618e-04 6.67184026e-05]
train_maes at epoch44: [0.05721165 0.01454117 0.01044402 0.00774096 0.00594443 0.00936056
 0.01683924 0.01282954 0.01671321 0.00765242]
test_loss at epoch44: 0.0005310546257533133
test_mses at epoch44: [3.43488527e-02 2.68255139e-04 5.47411337e-04 3.86135356e-05
 2.02758481e-04 2.82286993e-03 2.06998759e-04 1.32393132e-04
 6.31491711e-04 9.25560182e-05]
test_maes at epoch44: [0.18033084 0.01622872 0.02249712 0.0044439  0.01350818 0.05181917
 0.013201   0.01149506 0.02422027 0.00933845]

train_loss at epoch45: 0.00012987323862034827
train_mses at epoch45: [2.41454760e-03 2.73179210e-05 1.97653377e-04 1.37180021e-04
 7.60267341e-05 6.75556061e-04 2.95089243e-04 3.99060016e-05
 1.36692649e-04 2.08051532e-04]
train_maes at epoch45: [0.04149979 0.00397068 0.013171   0.01112286 0.00847518 0.02599124
 0.01341623 0.00495614 0.01145406 0.01193433]
test_loss at epoch45: 0.0004919972852803767
test_mses at epoch45: [3.20697927e-02 2.63974488e-04 4.83783895e-04 4.22209012e-05
 1.76395380e-04 2.58551267e-03 2.02663133e-04 1.21577645e-04
 5.94240999e-04 8.52726209e-05]
test_maes at epoch45: [0.17373052 0.01610457 0.0209913  0.00477382 0.01245911 0.04940445
 0.01299784 0.01101304 0.02339653 0.00894825]

train_loss at epoch46: 0.00014404109970200807
train_mses at epoch46: [6.39149143e-03 7.11419777e-06 2.32539909e-04 6.38150764e-04
 6.93593738e-05 2.40023633e-04 8.50998242e-05 9.11211462e-05
 7.11684011e-05 1.91895684e-04]
train_maes at epoch46: [0.07794732 0.00266484 0.01128293 0.01997732 0.00608201 0.01192481
 0.00786735 0.00918075 0.00813793 0.01361766]
test_loss at epoch46: 0.00044955103658139706
test_mses at epoch46: [2.97248650e-02 2.57970987e-04 4.16306744e-04 4.16416633e-05
 1.50671835e-04 2.32972063e-03 1.92770279e-04 1.08379165e-04
 5.49167279e-04 7.47874461e-05]
test_maes at epoch46: [0.16672473 0.01592646 0.01928121 0.00472559 0.01134758 0.04668107
 0.01257402 0.01039496 0.02236668 0.00835227]

train_loss at epoch47: 0.0003070887760259211
train_mses at epoch47: [1.05797141e-02 3.21953700e-04 4.73154243e-04 7.97106540e-05
 1.51568179e-06 1.76100860e-03 3.23207546e-04 3.14292003e-04
 4.10761737e-04 7.94824560e-05]
train_maes at epoch47: [0.09938724 0.01562191 0.02154092 0.00887675 0.0012274  0.04196139
 0.01766102 0.01370011 0.01965657 0.00666598]
test_loss at epoch47: 0.0004207789897918701
test_mses at epoch47: [2.81041097e-02 2.51083760e-04 3.71552548e-04 4.08661461e-05
 1.30675103e-04 2.16591955e-03 1.94835575e-04 1.00760295e-04
 5.11020238e-04 6.34160937e-05]
test_maes at epoch47: [0.16183868 0.01572229 0.01808966 0.0046708  0.01041491 0.04489012
 0.0126519  0.01002166 0.02147742 0.00765452]

train_loss at epoch48: 0.00015115077258087695
train_mses at epoch48: [3.96800668e-03 7.33631878e-05 1.33765136e-04 4.75328310e-04
 2.47485830e-05 3.18385433e-04 1.96825662e-04 4.96129751e-04
 6.23245899e-05 1.93359546e-04]
train_maes at epoch48: [0.05381541 0.00679619 0.01136652 0.02174768 0.00402808 0.01325369
 0.0112724  0.01604954 0.0075009  0.01243468]
test_loss at epoch48: 0.0004152058681938797
test_mses at epoch48: [2.78594920e-02 2.56918321e-04 3.58120646e-04 3.85630513e-05
 1.19267924e-04 2.14516848e-03 2.07759340e-04 1.00799010e-04
 4.83117645e-04 5.72233252e-05]
test_maes at epoch48: [0.16128826 0.0159215  0.01774952 0.00449003 0.00986179 0.04470277
 0.0131991  0.01002508 0.02082023 0.00725557]

train_loss at epoch49: 6.508031219709665e-05
train_mses at epoch49: [5.57633858e-06 1.10266637e-04 5.25050830e-05 1.35998587e-04
 2.87443533e-05 2.74189452e-04 8.90681414e-05 2.29184825e-04
 6.33212696e-05 3.30568808e-05]
train_maes at epoch49: [0.00236085 0.00999389 0.00523341 0.01111523 0.00466921 0.01240967
 0.00678918 0.01364896 0.00635066 0.00571502]
test_loss at epoch49: 0.0004199257236905396
test_mses at epoch49: [2.81875510e-02 2.59667826e-04 3.58537539e-04 3.40357651e-05
 1.13523509e-04 2.18863286e-03 2.27546586e-04 1.07278152e-04
 4.65820705e-04 5.36056610e-05]
test_maes at epoch49: [0.16254941 0.01602001 0.01780225 0.00418629 0.00958766 0.04525612
 0.01397717 0.01034607 0.02041218 0.0070129 ]

